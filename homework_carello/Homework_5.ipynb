{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5 Homework: Neural Networks & LVQ\n",
    "\n",
    "**Goal:** Understand the mechanics of Neural Networks and Learning Vector Quantization (LVQ) by implementing key components yourself.\n",
    "\n",
    "## Instructions\n",
    "1.  Run the initialization cells.\n",
    "2.  Navigate to **Exercise 1** and **Exercise 2**.\n",
    "3.  Fill in the missing code marked with `### YOUR CODE HERE ###`.\n",
    "4.  Run the test cells to verify your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Neural Networks\n",
    "\n",
    "In this exercise, you will complete a simple Feedforward Neural Network class.\n",
    "\n",
    "**Tasks:**\n",
    "1.  Implement `sigmoid_derivative`.\n",
    "2.  Complete the `forward` pass for the second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights\n",
    "        np.random.seed(42)\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the sigmoid function.\n",
    "        Formula: sigmoid_derivative(x) = x * (1 - x)\n",
    "        (Assuming x is already the sigmoid output)\n",
    "        \"\"\"\n",
    "        # Placeholder: Students need to implement this\n",
    "        # ### YOUR CODE HERE ###\n",
    "        return x * (1 - x)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Perform forward propagation.\n",
    "        \"\"\"\n",
    "        # Layer 1\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        \n",
    "        # Layer 2\n",
    "        # Placeholder: Implement the forward pass for the second layer\n",
    "        # Calculate self.z2 and self.a2 (output)\n",
    "        # ### YOUR CODE HERE ###\n",
    "     \n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        \"\"\"\n",
    "        Perform backward propagation and update weights.\n",
    "        (Simplified for this exercise to focus on Forward/Activation)\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "        error = output - y\n",
    "        # Full backprop implementation omitted for brevity in this specific exercise task\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        loss_history = []\n",
    "        for i in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            # Simple MSE loss\n",
    "            loss = np.mean(np.square(y - output))\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            \n",
    "        return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimpleNN...\n",
      "NN Training completed. Final Loss: 0.2832\n",
      "Warning: Loss is high. Did you implement the forward pass correctly?\n"
     ]
    }
   ],
   "source": [
    "# TEST EXERCISE 1\n",
    "print(\"Testing SimpleNN...\")\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([[0], [1], [1], [0]]) # XOR problem\n",
    "\n",
    "nn = SimpleNN(input_size=2, hidden_size=4, output_size=1)\n",
    "losses = nn.train(X, y, epochs=100, learning_rate=0.1)\n",
    "print(f\"NN Training completed. Final Loss: {losses[-1]:.4f}\")\n",
    "\n",
    "if losses[-1] > 0.24:\n",
    "    print(\"Warning: Loss is high. Did you implement the forward pass correctly?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Learning Vector Quantization (LVQ)\n",
    "\n",
    "In this exercise, you will implement the prototype update rule for LVQ.\n",
    "\n",
    "**Task:**\n",
    "1.  Implement the update logic inside the `train` method.\n",
    "    *   If the class matches: Move prototype **closer** to input.\n",
    "    *   If the class differs: Move prototype **away** from input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ:\n",
    "    def __init__(self, n_prototypes, n_features, n_classes):\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        # Initialize prototypes randomly\n",
    "        self.prototypes = np.random.randn(n_prototypes, n_features)\n",
    "        self.prototype_labels = np.array([i % n_classes for i in range(n_prototypes)])\n",
    "        \n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            for i, x in enumerate(X):\n",
    "                # 1. Find nearest prototype (Best Matching Unit - BMU)\n",
    "                distances = np.linalg.norm(self.prototypes - x, axis=1)\n",
    "                bmu_idx = np.argmin(distances)\n",
    "                \n",
    "                # 2. Update prototype\n",
    "                # Formula: w_new = w_old +/- alpha * (x - w_old)\n",
    "                # ### YOUR CODE HERE ###\n",
    "             \n",
    "                if self.prototype_labels[bmu_idx] == y[i]:\n",
    "                    # Move closer\n",
    "                   self.prototypes[bmu_idx] += learning_rate * (x - self.prototypes[bmu_idx])\n",
    "                   \n",
    "                else:\n",
    "                    # Move away\n",
    "                    self.prototypes[bmu_idx] -= learning_rate * (x - self.prototypes[bmu_idx])\n",
    "                    \n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = np.linalg.norm(self.prototypes - x, axis=1)\n",
    "            bmu_idx = np.argmin(distances)\n",
    "            predictions.append(self.prototype_labels[bmu_idx])\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LVQ...\n",
      "LVQ Predictions: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# TEST EXERCISE 2\n",
    "print(\"Testing LVQ...\")\n",
    "# Synthetic data: two clusters\n",
    "X_lvq = np.concatenate([np.random.randn(10, 2), np.random.randn(10, 2) + 3])\n",
    "y_lvq = np.array([0]*10 + [1]*10)\n",
    "\n",
    "lvq = LVQ(n_prototypes=2, n_features=2, n_classes=2)\n",
    "lvq.train(X_lvq, y_lvq, epochs=20, learning_rate=0.1)\n",
    "preds = lvq.predict(X_lvq)\n",
    "print(f\"LVQ Predictions: {preds}\")\n",
    "\n",
    "acc = np.mean(preds == y_lvq)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "if acc < 0.6:\n",
    "    print(\"Warning: Accuracy is low. Check your update rule implementation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
